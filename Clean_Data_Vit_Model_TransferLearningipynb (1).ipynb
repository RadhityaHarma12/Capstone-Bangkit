{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_O06Li2Auf2"
      },
      "source": [
        "# **Introduction**\n",
        "We are going through to make a classifier for rock, paper, and scissors images using Convolutional Neural Network (CNN) with the help of TensorFlow and Keras. We also going to use Hyperparameter Tuning to help find the optimal model. Happy exploring!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G3pqQJ6tq0B"
      },
      "source": [
        "# **Library**\n",
        "## Import Libraries and Packages\n",
        "The main library for this project are TensorFlow and its package Keras. So, the first thing you need is to import TensorFlow (make sure you already install the TensorFlow) and Keras will right away imported too. Then to create a new data from our dataset we use ImageDataGenerator from Keras for our image augmentation step.\n",
        "\n",
        "Note: There are some libraries present in the code cells below this section because I want to show what those libraries do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RTHwb-Ikmam4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyGW0FTkvLBl"
      },
      "source": [
        "# **Data Preparation**\n",
        "## Download and Extract The Dataset\n",
        "Next, we are going to download the dataset using wget command from the link that have been provided from my learning platform you may use it as well if you run it through Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFHffmT8B6s8",
        "outputId": "b25de942-9ea0-4972-bc8a-fe2869903f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQd340z8vQrZ"
      },
      "source": [
        "Extract the zip file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KU3mVvzEmhLo"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# Open the zip file\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/FER13_4_cleaner.zip', 'r') as zip_ref:\n",
        "    # Extract all the files to the current directory\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DVu1pkJuooCR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "\n",
        "# Define the pre-trained model and processor\n",
        "model_name = \"trpakov/vit-face-expression\"\n",
        "processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "model = AutoModelForImageClassification.from_pretrained(model_name)\n",
        "\n",
        "# Add a new layer to the model\n",
        "model.classifier = torch.nn.Linear(model.config.hidden_size, 5)\n",
        "\n",
        "# Define the data transforms using the processor\n",
        "def preprocess_image(image):\n",
        "    inputs = processor(image, return_tensors=\"pt\")\n",
        "    return inputs[\"pixel_values\"].squeeze(0)\n",
        "\n",
        "# Load the data using ImageFolder\n",
        "train_dataset = torchvision.datasets.ImageFolder(root='/content/FER13_cleaner/train', transform=preprocess_image)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root='/content/FER13_cleaner/test', transform=preprocess_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vaIc53yMMBKl"
      },
      "outputs": [],
      "source": [
        "# Define the data loaders\n",
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Set the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXSltvVbMKg6",
        "outputId": "1aadf0b2-3368-4e21-be8e-e4a0b5a96652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Train Accuracy: 0.9643, Train Loss: 0.19622654114781174\n",
            "Epoch 1, Test Accuracy: 0.7651\n",
            "Epoch 2, Train Accuracy: 0.9785, Train Loss: 0.08206585861940582\n",
            "Epoch 2, Test Accuracy: 0.7434\n",
            "Epoch 3, Train Accuracy: 0.9827, Train Loss: 0.06336910536474394\n",
            "Epoch 3, Test Accuracy: 0.7634\n",
            "Epoch 4, Train Accuracy: 0.9862, Train Loss: 0.049064329871668214\n",
            "Epoch 4, Test Accuracy: 0.7571\n",
            "Epoch 5, Train Accuracy: 0.9890, Train Loss: 0.039747174446252184\n",
            "Epoch 5, Test Accuracy: 0.7628\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    total_correct = 0\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        images, labels = batch\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "        total_loss += loss.item()\n",
        "    accuracy = total_correct / len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1}, Train Accuracy: {accuracy:.4f}, Train Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate the model on the test set\n",
        "    with torch.no_grad():\n",
        "        total_correct = 0\n",
        "        for batch in test_loader:\n",
        "            images, labels = batch\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "        accuracy = total_correct / len(test_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}, Test Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i7sDBRgete9V"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'swin_transformer_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/content/swin_transformer_model.pth', map_location='cpu'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "urr4uFow-zf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32ef820-159e-468a-8acc-0fc3b1165874"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTSdpaAttention(\n",
              "            (attention): ViTSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input = torch.rand((1, 3, 224, 224))"
      ],
      "metadata": {
        "id": "iNWiJpbV-1Xo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pindahkan model ke GPU jika tersedia\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "JF4oxqfK-28i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd31cc1-ce06-4d77-f529-0732afc711c5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTSdpaAttention(\n",
              "            (attention): ViTSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n",
        "torch.onnx.export(\n",
        "    model,                  # PyTorch Model\n",
        "    sample_input.to(device),                    # Input tensor\n",
        "    'odel-swin.onnx',        # Output file (eg. 'output_model.onnx')\n",
        "    opset_version=14,       # Operator support version (updated to 14)\n",
        "    export_params=True,    # Export model parameters\n",
        "    verbose=True           # Tampilkan pesan debug\n",
        ")"
      ],
      "metadata": {
        "id": "qW7OY0wC-4_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa0a772b-f068-46f4-a985-f26105a2aabd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/15.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/15.9 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/15.9 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11.6/15.9 MB\u001b[0m \u001b[31m156.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m204.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m204.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/modeling_vit.py:164: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if num_channels != self.num_channels:\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/modeling_vit.py:170: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if height != self.image_size[0] or width != self.image_size[1]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the ONNX model\n",
        "model = onnx.load(\"odel-swin.onnx\")\n",
        "\n",
        "# Check that the IR is well formed\n",
        "onnx.checker.check_model(model)\n",
        "\n",
        "# Print a Human readable representation of the graph\n",
        "onnx.helper.printable_graph(model.graph)"
      ],
      "metadata": {
        "id": "EeVrZ-09-9pr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "2f63899b-5d61-4a10-e9c1-4ddad8a5922e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'graph main_graph (\\n  %input.1[FLOAT, 1x3x224x224]\\n) initializers (\\n  %vit.embeddings.cls_token[FLOAT, 1x1x768]\\n  %vit.embeddings.position_embeddings[FLOAT, 1x197x768]\\n  %vit.embeddings.patch_embeddings.projection.weight[FLOAT, 768x3x16x16]\\n  %vit.embeddings.patch_embeddings.projection.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.0.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.0.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.0.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.0.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.1.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.1.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.1.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.1.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.2.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.2.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.2.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.2.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.3.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.3.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.3.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.3.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.4.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.4.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.4.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.4.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.5.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.5.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.5.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.5.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.6.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.6.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.6.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.6.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.7.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.7.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.7.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.7.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.8.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.8.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.8.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.8.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.9.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.9.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.9.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.9.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.10.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.10.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.10.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.10.layernorm_after.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.attention.attention.query.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.attention.attention.key.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.attention.attention.value.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\\n  %vit.encoder.layer.11.output.dense.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.layernorm_before.weight[FLOAT, 768]\\n  %vit.encoder.layer.11.layernorm_before.bias[FLOAT, 768]\\n  %vit.encoder.layer.11.layernorm_after.weight[FLOAT, 768]\\n  %vit.encoder.layer.11.layernorm_after.bias[FLOAT, 768]\\n  %vit.layernorm.weight[FLOAT, 768]\\n  %vit.layernorm.bias[FLOAT, 768]\\n  %classifier.weight[FLOAT, 5x768]\\n  %classifier.bias[FLOAT, 5]\\n  %onnx::MatMul_1646[FLOAT, 768x768]\\n  %onnx::MatMul_1647[FLOAT, 768x768]\\n  %onnx::MatMul_1653[FLOAT, 768x768]\\n  %onnx::MatMul_1668[FLOAT, 768x768]\\n  %onnx::MatMul_1669[FLOAT, 768x3072]\\n  %onnx::MatMul_1670[FLOAT, 3072x768]\\n  %onnx::MatMul_1671[FLOAT, 768x768]\\n  %onnx::MatMul_1672[FLOAT, 768x768]\\n  %onnx::MatMul_1678[FLOAT, 768x768]\\n  %onnx::MatMul_1693[FLOAT, 768x768]\\n  %onnx::MatMul_1694[FLOAT, 768x3072]\\n  %onnx::MatMul_1695[FLOAT, 3072x768]\\n  %onnx::MatMul_1696[FLOAT, 768x768]\\n  %onnx::MatMul_1697[FLOAT, 768x768]\\n  %onnx::MatMul_1703[FLOAT, 768x768]\\n  %onnx::MatMul_1718[FLOAT, 768x768]\\n  %onnx::MatMul_1719[FLOAT, 768x3072]\\n  %onnx::MatMul_1720[FLOAT, 3072x768]\\n  %onnx::MatMul_1721[FLOAT, 768x768]\\n  %onnx::MatMul_1722[FLOAT, 768x768]\\n  %onnx::MatMul_1728[FLOAT, 768x768]\\n  %onnx::MatMul_1743[FLOAT, 768x768]\\n  %onnx::MatMul_1744[FLOAT, 768x3072]\\n  %onnx::MatMul_1745[FLOAT, 3072x768]\\n  %onnx::MatMul_1746[FLOAT, 768x768]\\n  %onnx::MatMul_1747[FLOAT, 768x768]\\n  %onnx::MatMul_1753[FLOAT, 768x768]\\n  %onnx::MatMul_1768[FLOAT, 768x768]\\n  %onnx::MatMul_1769[FLOAT, 768x3072]\\n  %onnx::MatMul_1770[FLOAT, 3072x768]\\n  %onnx::MatMul_1771[FLOAT, 768x768]\\n  %onnx::MatMul_1772[FLOAT, 768x768]\\n  %onnx::MatMul_1778[FLOAT, 768x768]\\n  %onnx::MatMul_1793[FLOAT, 768x768]\\n  %onnx::MatMul_1794[FLOAT, 768x3072]\\n  %onnx::MatMul_1795[FLOAT, 3072x768]\\n  %onnx::MatMul_1796[FLOAT, 768x768]\\n  %onnx::MatMul_1797[FLOAT, 768x768]\\n  %onnx::MatMul_1803[FLOAT, 768x768]\\n  %onnx::MatMul_1818[FLOAT, 768x768]\\n  %onnx::MatMul_1819[FLOAT, 768x3072]\\n  %onnx::MatMul_1820[FLOAT, 3072x768]\\n  %onnx::MatMul_1821[FLOAT, 768x768]\\n  %onnx::MatMul_1822[FLOAT, 768x768]\\n  %onnx::MatMul_1828[FLOAT, 768x768]\\n  %onnx::MatMul_1843[FLOAT, 768x768]\\n  %onnx::MatMul_1844[FLOAT, 768x3072]\\n  %onnx::MatMul_1845[FLOAT, 3072x768]\\n  %onnx::MatMul_1846[FLOAT, 768x768]\\n  %onnx::MatMul_1847[FLOAT, 768x768]\\n  %onnx::MatMul_1853[FLOAT, 768x768]\\n  %onnx::MatMul_1868[FLOAT, 768x768]\\n  %onnx::MatMul_1869[FLOAT, 768x3072]\\n  %onnx::MatMul_1870[FLOAT, 3072x768]\\n  %onnx::MatMul_1871[FLOAT, 768x768]\\n  %onnx::MatMul_1872[FLOAT, 768x768]\\n  %onnx::MatMul_1878[FLOAT, 768x768]\\n  %onnx::MatMul_1893[FLOAT, 768x768]\\n  %onnx::MatMul_1894[FLOAT, 768x3072]\\n  %onnx::MatMul_1895[FLOAT, 3072x768]\\n  %onnx::MatMul_1896[FLOAT, 768x768]\\n  %onnx::MatMul_1897[FLOAT, 768x768]\\n  %onnx::MatMul_1903[FLOAT, 768x768]\\n  %onnx::MatMul_1918[FLOAT, 768x768]\\n  %onnx::MatMul_1919[FLOAT, 768x3072]\\n  %onnx::MatMul_1920[FLOAT, 3072x768]\\n  %onnx::MatMul_1921[FLOAT, 768x768]\\n  %onnx::MatMul_1922[FLOAT, 768x768]\\n  %onnx::MatMul_1928[FLOAT, 768x768]\\n  %onnx::MatMul_1943[FLOAT, 768x768]\\n  %onnx::MatMul_1944[FLOAT, 768x3072]\\n  %onnx::MatMul_1945[FLOAT, 3072x768]\\n) {\\n  %/vit/embeddings/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/embeddings/patch_embeddings/projection/Conv_output_0 = Conv[dilations = [1, 1], group = 1, kernel_shape = [16, 16], pads = [0, 0, 0, 0], strides = [16, 16]](%input.1, %vit.embeddings.patch_embeddings.projection.weight, %vit.embeddings.patch_embeddings.projection.bias)\\n  %/vit/embeddings/patch_embeddings/Shape_output_0 = Shape(%/vit/embeddings/patch_embeddings/projection/Conv_output_0)\\n  %/vit/embeddings/patch_embeddings/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/embeddings/patch_embeddings/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/embeddings/patch_embeddings/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/embeddings/patch_embeddings/Slice_output_0 = Slice(%/vit/embeddings/patch_embeddings/Shape_output_0, %/vit/embeddings/patch_embeddings/Constant_1_output_0, %/vit/embeddings/patch_embeddings/Constant_2_output_0, %/vit/embeddings/patch_embeddings/Constant_output_0)\\n  %/vit/embeddings/patch_embeddings/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/embeddings/patch_embeddings/Concat_output_0 = Concat[axis = 0](%/vit/embeddings/patch_embeddings/Slice_output_0, %/vit/embeddings/patch_embeddings/Constant_3_output_0)\\n  %/vit/embeddings/patch_embeddings/Reshape_output_0 = Reshape[allowzero = 0](%/vit/embeddings/patch_embeddings/projection/Conv_output_0, %/vit/embeddings/patch_embeddings/Concat_output_0)\\n  %/vit/embeddings/patch_embeddings/Transpose_output_0 = Transpose[perm = [0, 2, 1]](%/vit/embeddings/patch_embeddings/Reshape_output_0)\\n  %/vit/embeddings/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/embeddings/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/embeddings/ConstantOfShape_output_0 = ConstantOfShape[value = <Tensor>](%/vit/embeddings/Constant_2_output_0)\\n  %/vit/embeddings/Constant_3_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/embeddings/Mul_output_0 = Mul(%/vit/embeddings/ConstantOfShape_output_0, %/vit/embeddings/Constant_3_output_0)\\n  %/vit/embeddings/Equal_output_0 = Equal(%/vit/embeddings/Constant_1_output_0, %/vit/embeddings/Mul_output_0)\\n  %/vit/embeddings/Where_output_0 = Where(%/vit/embeddings/Equal_output_0, %/vit/embeddings/ConstantOfShape_output_0, %/vit/embeddings/Constant_1_output_0)\\n  %/vit/embeddings/Expand_output_0 = Expand(%vit.embeddings.cls_token, %/vit/embeddings/Where_output_0)\\n  %/vit/embeddings/Concat_output_0 = Concat[axis = 1](%/vit/embeddings/Expand_output_0, %/vit/embeddings/patch_embeddings/Transpose_output_0)\\n  %/vit/embeddings/Add_output_0 = Add(%/vit/embeddings/Concat_output_0, %vit.embeddings.position_embeddings)\\n  %/vit/encoder/layer.0/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/embeddings/Add_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/Sub_output_0 = Sub(%/vit/embeddings/Add_output_0, %/vit/encoder/layer.0/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.0/layernorm_before/Sub_output_0, %/vit/encoder/layer.0/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.0/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.0/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.0/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.0/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.0/layernorm_before/Sub_output_0, %/vit/encoder/layer.0/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.0/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.0/layernorm_before/Div_output_0, %vit.encoder.layer.0.layernorm_before.weight)\\n  %/vit/encoder/layer.0/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.0/layernorm_before/Mul_output_0, %vit.encoder.layer.0.layernorm_before.bias)\\n  %/vit/encoder/layer.0/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/layernorm_before/Add_1_output_0, %onnx::MatMul_1646)\\n  %/vit/encoder/layer.0/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.0.attention.attention.query.bias, %/vit/encoder/layer.0/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.0/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/layernorm_before/Add_1_output_0, %onnx::MatMul_1647)\\n  %/vit/encoder/layer.0/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.0.attention.attention.key.bias, %/vit/encoder/layer.0/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.0/attention/attention/key/Add_output_0, %/vit/encoder/layer.0/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.0/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/layernorm_before/Add_1_output_0, %onnx::MatMul_1653)\\n  %/vit/encoder/layer.0/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.0.attention.attention.value.bias, %/vit/encoder/layer.0/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.0/attention/attention/value/Add_output_0, %/vit/encoder/layer.0/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.0/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.0/attention/attention/query/Add_output_0, %/vit/encoder/layer.0/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.0/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.0/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.0/attention/attention/Shape_output_0, %/vit/encoder/layer.0/attention/attention/Constant_3_output_0, %/vit/encoder/layer.0/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.0/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.0/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.0/attention/attention/Constant_5_output_0, %/vit/encoder/layer.0/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.0/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.0/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.0/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.0/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.0/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.0/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.0/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.0/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.0/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/attention/attention/Mul_output_0, %/vit/encoder/layer.0/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.0/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.0/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.0/attention/attention/Softmax_output_0, %/vit/encoder/layer.0/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.0/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.0/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.0/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.0/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.0/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.0/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/attention/attention/Reshape_3_output_0, %onnx::MatMul_1668)\\n  %/vit/encoder/layer.0/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.0.attention.output.dense.bias, %/vit/encoder/layer.0/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.0/Add_output_0 = Add(%/vit/encoder/layer.0/attention/output/dense/Add_output_0, %/vit/embeddings/Add_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.0/Add_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.0/Add_output_0, %/vit/encoder/layer.0/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.0/layernorm_after/Sub_output_0, %/vit/encoder/layer.0/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.0/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.0/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.0/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.0/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.0/layernorm_after/Sub_output_0, %/vit/encoder/layer.0/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.0/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.0/layernorm_after/Div_output_0, %vit.encoder.layer.0.layernorm_after.weight)\\n  %/vit/encoder/layer.0/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.0/layernorm_after/Mul_output_0, %vit.encoder.layer.0.layernorm_after.bias)\\n  %/vit/encoder/layer.0/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/layernorm_after/Add_1_output_0, %onnx::MatMul_1669)\\n  %/vit/encoder/layer.0/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.0.intermediate.dense.bias, %/vit/encoder/layer.0/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.0/intermediate/dense/Add_output_0, %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.0/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.0/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.0/intermediate/dense/Add_output_0, %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.0/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.0/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.0/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.0/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1670)\\n  %/vit/encoder/layer.0/output/dense/Add_output_0 = Add(%vit.encoder.layer.0.output.dense.bias, %/vit/encoder/layer.0/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.0/output/Add_output_0 = Add(%/vit/encoder/layer.0/output/dense/Add_output_0, %/vit/encoder/layer.0/Add_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.0/output/Add_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.0/output/Add_output_0, %/vit/encoder/layer.1/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.1/layernorm_before/Sub_output_0, %/vit/encoder/layer.1/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.1/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.1/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.1/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.1/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.1/layernorm_before/Sub_output_0, %/vit/encoder/layer.1/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.1/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.1/layernorm_before/Div_output_0, %vit.encoder.layer.1.layernorm_before.weight)\\n  %/vit/encoder/layer.1/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.1/layernorm_before/Mul_output_0, %vit.encoder.layer.1.layernorm_before.bias)\\n  %/vit/encoder/layer.1/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/layernorm_before/Add_1_output_0, %onnx::MatMul_1671)\\n  %/vit/encoder/layer.1/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.1.attention.attention.query.bias, %/vit/encoder/layer.1/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.1/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/layernorm_before/Add_1_output_0, %onnx::MatMul_1672)\\n  %/vit/encoder/layer.1/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.1.attention.attention.key.bias, %/vit/encoder/layer.1/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.1/attention/attention/key/Add_output_0, %/vit/encoder/layer.1/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.1/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/layernorm_before/Add_1_output_0, %onnx::MatMul_1678)\\n  %/vit/encoder/layer.1/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.1.attention.attention.value.bias, %/vit/encoder/layer.1/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.1/attention/attention/value/Add_output_0, %/vit/encoder/layer.1/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.1/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.1/attention/attention/query/Add_output_0, %/vit/encoder/layer.1/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.1/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.1/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.1/attention/attention/Shape_output_0, %/vit/encoder/layer.1/attention/attention/Constant_3_output_0, %/vit/encoder/layer.1/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.1/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.1/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.1/attention/attention/Constant_5_output_0, %/vit/encoder/layer.1/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.1/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.1/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.1/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.1/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.1/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.1/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.1/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.1/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.1/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/attention/attention/Mul_output_0, %/vit/encoder/layer.1/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.1/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.1/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.1/attention/attention/Softmax_output_0, %/vit/encoder/layer.1/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.1/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.1/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.1/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.1/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.1/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.1/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/attention/attention/Reshape_3_output_0, %onnx::MatMul_1693)\\n  %/vit/encoder/layer.1/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.1.attention.output.dense.bias, %/vit/encoder/layer.1/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.1/Add_output_0 = Add(%/vit/encoder/layer.1/attention/output/dense/Add_output_0, %/vit/encoder/layer.0/output/Add_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.1/Add_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.1/Add_output_0, %/vit/encoder/layer.1/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.1/layernorm_after/Sub_output_0, %/vit/encoder/layer.1/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.1/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.1/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.1/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.1/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.1/layernorm_after/Sub_output_0, %/vit/encoder/layer.1/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.1/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.1/layernorm_after/Div_output_0, %vit.encoder.layer.1.layernorm_after.weight)\\n  %/vit/encoder/layer.1/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.1/layernorm_after/Mul_output_0, %vit.encoder.layer.1.layernorm_after.bias)\\n  %/vit/encoder/layer.1/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/layernorm_after/Add_1_output_0, %onnx::MatMul_1694)\\n  %/vit/encoder/layer.1/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.1.intermediate.dense.bias, %/vit/encoder/layer.1/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.1/intermediate/dense/Add_output_0, %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.1/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.1/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.1/intermediate/dense/Add_output_0, %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.1/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.1/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.1/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.1/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1695)\\n  %/vit/encoder/layer.1/output/dense/Add_output_0 = Add(%vit.encoder.layer.1.output.dense.bias, %/vit/encoder/layer.1/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.1/output/Add_output_0 = Add(%/vit/encoder/layer.1/output/dense/Add_output_0, %/vit/encoder/layer.1/Add_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.1/output/Add_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.1/output/Add_output_0, %/vit/encoder/layer.2/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.2/layernorm_before/Sub_output_0, %/vit/encoder/layer.2/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.2/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.2/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.2/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.2/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.2/layernorm_before/Sub_output_0, %/vit/encoder/layer.2/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.2/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.2/layernorm_before/Div_output_0, %vit.encoder.layer.2.layernorm_before.weight)\\n  %/vit/encoder/layer.2/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.2/layernorm_before/Mul_output_0, %vit.encoder.layer.2.layernorm_before.bias)\\n  %/vit/encoder/layer.2/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/layernorm_before/Add_1_output_0, %onnx::MatMul_1696)\\n  %/vit/encoder/layer.2/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.2.attention.attention.query.bias, %/vit/encoder/layer.2/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.2/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/layernorm_before/Add_1_output_0, %onnx::MatMul_1697)\\n  %/vit/encoder/layer.2/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.2.attention.attention.key.bias, %/vit/encoder/layer.2/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.2/attention/attention/key/Add_output_0, %/vit/encoder/layer.2/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.2/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/layernorm_before/Add_1_output_0, %onnx::MatMul_1703)\\n  %/vit/encoder/layer.2/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.2.attention.attention.value.bias, %/vit/encoder/layer.2/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.2/attention/attention/value/Add_output_0, %/vit/encoder/layer.2/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.2/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.2/attention/attention/query/Add_output_0, %/vit/encoder/layer.2/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.2/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.2/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.2/attention/attention/Shape_output_0, %/vit/encoder/layer.2/attention/attention/Constant_3_output_0, %/vit/encoder/layer.2/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.2/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.2/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.2/attention/attention/Constant_5_output_0, %/vit/encoder/layer.2/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.2/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.2/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.2/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.2/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.2/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.2/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.2/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.2/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.2/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/attention/attention/Mul_output_0, %/vit/encoder/layer.2/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.2/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.2/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.2/attention/attention/Softmax_output_0, %/vit/encoder/layer.2/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.2/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.2/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.2/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.2/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.2/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.2/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/attention/attention/Reshape_3_output_0, %onnx::MatMul_1718)\\n  %/vit/encoder/layer.2/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.2.attention.output.dense.bias, %/vit/encoder/layer.2/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.2/Add_output_0 = Add(%/vit/encoder/layer.2/attention/output/dense/Add_output_0, %/vit/encoder/layer.1/output/Add_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.2/Add_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.2/Add_output_0, %/vit/encoder/layer.2/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.2/layernorm_after/Sub_output_0, %/vit/encoder/layer.2/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.2/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.2/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.2/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.2/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.2/layernorm_after/Sub_output_0, %/vit/encoder/layer.2/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.2/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.2/layernorm_after/Div_output_0, %vit.encoder.layer.2.layernorm_after.weight)\\n  %/vit/encoder/layer.2/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.2/layernorm_after/Mul_output_0, %vit.encoder.layer.2.layernorm_after.bias)\\n  %/vit/encoder/layer.2/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/layernorm_after/Add_1_output_0, %onnx::MatMul_1719)\\n  %/vit/encoder/layer.2/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.2.intermediate.dense.bias, %/vit/encoder/layer.2/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.2/intermediate/dense/Add_output_0, %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.2/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.2/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.2/intermediate/dense/Add_output_0, %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.2/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.2/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.2/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.2/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1720)\\n  %/vit/encoder/layer.2/output/dense/Add_output_0 = Add(%vit.encoder.layer.2.output.dense.bias, %/vit/encoder/layer.2/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.2/output/Add_output_0 = Add(%/vit/encoder/layer.2/output/dense/Add_output_0, %/vit/encoder/layer.2/Add_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.2/output/Add_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.2/output/Add_output_0, %/vit/encoder/layer.3/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.3/layernorm_before/Sub_output_0, %/vit/encoder/layer.3/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.3/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.3/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.3/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.3/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.3/layernorm_before/Sub_output_0, %/vit/encoder/layer.3/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.3/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.3/layernorm_before/Div_output_0, %vit.encoder.layer.3.layernorm_before.weight)\\n  %/vit/encoder/layer.3/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.3/layernorm_before/Mul_output_0, %vit.encoder.layer.3.layernorm_before.bias)\\n  %/vit/encoder/layer.3/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/layernorm_before/Add_1_output_0, %onnx::MatMul_1721)\\n  %/vit/encoder/layer.3/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.3.attention.attention.query.bias, %/vit/encoder/layer.3/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.3/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/layernorm_before/Add_1_output_0, %onnx::MatMul_1722)\\n  %/vit/encoder/layer.3/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.3.attention.attention.key.bias, %/vit/encoder/layer.3/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.3/attention/attention/key/Add_output_0, %/vit/encoder/layer.3/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.3/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/layernorm_before/Add_1_output_0, %onnx::MatMul_1728)\\n  %/vit/encoder/layer.3/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.3.attention.attention.value.bias, %/vit/encoder/layer.3/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.3/attention/attention/value/Add_output_0, %/vit/encoder/layer.3/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.3/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.3/attention/attention/query/Add_output_0, %/vit/encoder/layer.3/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.3/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.3/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.3/attention/attention/Shape_output_0, %/vit/encoder/layer.3/attention/attention/Constant_3_output_0, %/vit/encoder/layer.3/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.3/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.3/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.3/attention/attention/Constant_5_output_0, %/vit/encoder/layer.3/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.3/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.3/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.3/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.3/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.3/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.3/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.3/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.3/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.3/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/attention/attention/Mul_output_0, %/vit/encoder/layer.3/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.3/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.3/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.3/attention/attention/Softmax_output_0, %/vit/encoder/layer.3/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.3/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.3/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.3/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.3/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.3/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.3/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/attention/attention/Reshape_3_output_0, %onnx::MatMul_1743)\\n  %/vit/encoder/layer.3/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.3.attention.output.dense.bias, %/vit/encoder/layer.3/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.3/Add_output_0 = Add(%/vit/encoder/layer.3/attention/output/dense/Add_output_0, %/vit/encoder/layer.2/output/Add_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.3/Add_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.3/Add_output_0, %/vit/encoder/layer.3/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.3/layernorm_after/Sub_output_0, %/vit/encoder/layer.3/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.3/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.3/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.3/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.3/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.3/layernorm_after/Sub_output_0, %/vit/encoder/layer.3/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.3/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.3/layernorm_after/Div_output_0, %vit.encoder.layer.3.layernorm_after.weight)\\n  %/vit/encoder/layer.3/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.3/layernorm_after/Mul_output_0, %vit.encoder.layer.3.layernorm_after.bias)\\n  %/vit/encoder/layer.3/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/layernorm_after/Add_1_output_0, %onnx::MatMul_1744)\\n  %/vit/encoder/layer.3/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.3.intermediate.dense.bias, %/vit/encoder/layer.3/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.3/intermediate/dense/Add_output_0, %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.3/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.3/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.3/intermediate/dense/Add_output_0, %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.3/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.3/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.3/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.3/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1745)\\n  %/vit/encoder/layer.3/output/dense/Add_output_0 = Add(%vit.encoder.layer.3.output.dense.bias, %/vit/encoder/layer.3/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.3/output/Add_output_0 = Add(%/vit/encoder/layer.3/output/dense/Add_output_0, %/vit/encoder/layer.3/Add_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.3/output/Add_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.3/output/Add_output_0, %/vit/encoder/layer.4/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.4/layernorm_before/Sub_output_0, %/vit/encoder/layer.4/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.4/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.4/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.4/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.4/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.4/layernorm_before/Sub_output_0, %/vit/encoder/layer.4/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.4/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.4/layernorm_before/Div_output_0, %vit.encoder.layer.4.layernorm_before.weight)\\n  %/vit/encoder/layer.4/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.4/layernorm_before/Mul_output_0, %vit.encoder.layer.4.layernorm_before.bias)\\n  %/vit/encoder/layer.4/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/layernorm_before/Add_1_output_0, %onnx::MatMul_1746)\\n  %/vit/encoder/layer.4/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.4.attention.attention.query.bias, %/vit/encoder/layer.4/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.4/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/layernorm_before/Add_1_output_0, %onnx::MatMul_1747)\\n  %/vit/encoder/layer.4/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.4.attention.attention.key.bias, %/vit/encoder/layer.4/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.4/attention/attention/key/Add_output_0, %/vit/encoder/layer.4/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.4/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/layernorm_before/Add_1_output_0, %onnx::MatMul_1753)\\n  %/vit/encoder/layer.4/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.4.attention.attention.value.bias, %/vit/encoder/layer.4/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.4/attention/attention/value/Add_output_0, %/vit/encoder/layer.4/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.4/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.4/attention/attention/query/Add_output_0, %/vit/encoder/layer.4/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.4/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.4/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.4/attention/attention/Shape_output_0, %/vit/encoder/layer.4/attention/attention/Constant_3_output_0, %/vit/encoder/layer.4/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.4/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.4/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.4/attention/attention/Constant_5_output_0, %/vit/encoder/layer.4/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.4/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.4/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.4/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.4/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.4/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.4/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.4/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.4/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.4/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/attention/attention/Mul_output_0, %/vit/encoder/layer.4/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.4/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.4/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.4/attention/attention/Softmax_output_0, %/vit/encoder/layer.4/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.4/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.4/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.4/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.4/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.4/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.4/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/attention/attention/Reshape_3_output_0, %onnx::MatMul_1768)\\n  %/vit/encoder/layer.4/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.4.attention.output.dense.bias, %/vit/encoder/layer.4/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.4/Add_output_0 = Add(%/vit/encoder/layer.4/attention/output/dense/Add_output_0, %/vit/encoder/layer.3/output/Add_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.4/Add_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.4/Add_output_0, %/vit/encoder/layer.4/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.4/layernorm_after/Sub_output_0, %/vit/encoder/layer.4/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.4/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.4/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.4/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.4/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.4/layernorm_after/Sub_output_0, %/vit/encoder/layer.4/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.4/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.4/layernorm_after/Div_output_0, %vit.encoder.layer.4.layernorm_after.weight)\\n  %/vit/encoder/layer.4/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.4/layernorm_after/Mul_output_0, %vit.encoder.layer.4.layernorm_after.bias)\\n  %/vit/encoder/layer.4/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/layernorm_after/Add_1_output_0, %onnx::MatMul_1769)\\n  %/vit/encoder/layer.4/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.4.intermediate.dense.bias, %/vit/encoder/layer.4/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.4/intermediate/dense/Add_output_0, %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.4/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.4/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.4/intermediate/dense/Add_output_0, %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.4/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.4/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.4/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.4/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1770)\\n  %/vit/encoder/layer.4/output/dense/Add_output_0 = Add(%vit.encoder.layer.4.output.dense.bias, %/vit/encoder/layer.4/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.4/output/Add_output_0 = Add(%/vit/encoder/layer.4/output/dense/Add_output_0, %/vit/encoder/layer.4/Add_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.4/output/Add_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.4/output/Add_output_0, %/vit/encoder/layer.5/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.5/layernorm_before/Sub_output_0, %/vit/encoder/layer.5/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.5/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.5/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.5/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.5/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.5/layernorm_before/Sub_output_0, %/vit/encoder/layer.5/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.5/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.5/layernorm_before/Div_output_0, %vit.encoder.layer.5.layernorm_before.weight)\\n  %/vit/encoder/layer.5/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.5/layernorm_before/Mul_output_0, %vit.encoder.layer.5.layernorm_before.bias)\\n  %/vit/encoder/layer.5/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/layernorm_before/Add_1_output_0, %onnx::MatMul_1771)\\n  %/vit/encoder/layer.5/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.5.attention.attention.query.bias, %/vit/encoder/layer.5/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.5/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/layernorm_before/Add_1_output_0, %onnx::MatMul_1772)\\n  %/vit/encoder/layer.5/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.5.attention.attention.key.bias, %/vit/encoder/layer.5/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.5/attention/attention/key/Add_output_0, %/vit/encoder/layer.5/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.5/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/layernorm_before/Add_1_output_0, %onnx::MatMul_1778)\\n  %/vit/encoder/layer.5/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.5.attention.attention.value.bias, %/vit/encoder/layer.5/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.5/attention/attention/value/Add_output_0, %/vit/encoder/layer.5/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.5/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.5/attention/attention/query/Add_output_0, %/vit/encoder/layer.5/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.5/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.5/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.5/attention/attention/Shape_output_0, %/vit/encoder/layer.5/attention/attention/Constant_3_output_0, %/vit/encoder/layer.5/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.5/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.5/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.5/attention/attention/Constant_5_output_0, %/vit/encoder/layer.5/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.5/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.5/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.5/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.5/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.5/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.5/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.5/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.5/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.5/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/attention/attention/Mul_output_0, %/vit/encoder/layer.5/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.5/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.5/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.5/attention/attention/Softmax_output_0, %/vit/encoder/layer.5/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.5/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.5/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.5/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.5/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.5/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.5/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/attention/attention/Reshape_3_output_0, %onnx::MatMul_1793)\\n  %/vit/encoder/layer.5/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.5.attention.output.dense.bias, %/vit/encoder/layer.5/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.5/Add_output_0 = Add(%/vit/encoder/layer.5/attention/output/dense/Add_output_0, %/vit/encoder/layer.4/output/Add_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.5/Add_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.5/Add_output_0, %/vit/encoder/layer.5/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.5/layernorm_after/Sub_output_0, %/vit/encoder/layer.5/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.5/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.5/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.5/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.5/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.5/layernorm_after/Sub_output_0, %/vit/encoder/layer.5/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.5/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.5/layernorm_after/Div_output_0, %vit.encoder.layer.5.layernorm_after.weight)\\n  %/vit/encoder/layer.5/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.5/layernorm_after/Mul_output_0, %vit.encoder.layer.5.layernorm_after.bias)\\n  %/vit/encoder/layer.5/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/layernorm_after/Add_1_output_0, %onnx::MatMul_1794)\\n  %/vit/encoder/layer.5/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.5.intermediate.dense.bias, %/vit/encoder/layer.5/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.5/intermediate/dense/Add_output_0, %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.5/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.5/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.5/intermediate/dense/Add_output_0, %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.5/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.5/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.5/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.5/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1795)\\n  %/vit/encoder/layer.5/output/dense/Add_output_0 = Add(%vit.encoder.layer.5.output.dense.bias, %/vit/encoder/layer.5/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.5/output/Add_output_0 = Add(%/vit/encoder/layer.5/output/dense/Add_output_0, %/vit/encoder/layer.5/Add_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.5/output/Add_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.5/output/Add_output_0, %/vit/encoder/layer.6/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.6/layernorm_before/Sub_output_0, %/vit/encoder/layer.6/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.6/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.6/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.6/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.6/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.6/layernorm_before/Sub_output_0, %/vit/encoder/layer.6/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.6/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.6/layernorm_before/Div_output_0, %vit.encoder.layer.6.layernorm_before.weight)\\n  %/vit/encoder/layer.6/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.6/layernorm_before/Mul_output_0, %vit.encoder.layer.6.layernorm_before.bias)\\n  %/vit/encoder/layer.6/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/layernorm_before/Add_1_output_0, %onnx::MatMul_1796)\\n  %/vit/encoder/layer.6/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.6.attention.attention.query.bias, %/vit/encoder/layer.6/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.6/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/layernorm_before/Add_1_output_0, %onnx::MatMul_1797)\\n  %/vit/encoder/layer.6/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.6.attention.attention.key.bias, %/vit/encoder/layer.6/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.6/attention/attention/key/Add_output_0, %/vit/encoder/layer.6/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.6/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/layernorm_before/Add_1_output_0, %onnx::MatMul_1803)\\n  %/vit/encoder/layer.6/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.6.attention.attention.value.bias, %/vit/encoder/layer.6/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.6/attention/attention/value/Add_output_0, %/vit/encoder/layer.6/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.6/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.6/attention/attention/query/Add_output_0, %/vit/encoder/layer.6/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.6/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.6/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.6/attention/attention/Shape_output_0, %/vit/encoder/layer.6/attention/attention/Constant_3_output_0, %/vit/encoder/layer.6/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.6/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.6/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.6/attention/attention/Constant_5_output_0, %/vit/encoder/layer.6/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.6/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.6/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.6/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.6/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.6/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.6/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.6/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.6/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.6/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/attention/attention/Mul_output_0, %/vit/encoder/layer.6/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.6/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.6/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.6/attention/attention/Softmax_output_0, %/vit/encoder/layer.6/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.6/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.6/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.6/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.6/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.6/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.6/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/attention/attention/Reshape_3_output_0, %onnx::MatMul_1818)\\n  %/vit/encoder/layer.6/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.6.attention.output.dense.bias, %/vit/encoder/layer.6/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.6/Add_output_0 = Add(%/vit/encoder/layer.6/attention/output/dense/Add_output_0, %/vit/encoder/layer.5/output/Add_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.6/Add_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.6/Add_output_0, %/vit/encoder/layer.6/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.6/layernorm_after/Sub_output_0, %/vit/encoder/layer.6/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.6/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.6/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.6/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.6/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.6/layernorm_after/Sub_output_0, %/vit/encoder/layer.6/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.6/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.6/layernorm_after/Div_output_0, %vit.encoder.layer.6.layernorm_after.weight)\\n  %/vit/encoder/layer.6/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.6/layernorm_after/Mul_output_0, %vit.encoder.layer.6.layernorm_after.bias)\\n  %/vit/encoder/layer.6/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/layernorm_after/Add_1_output_0, %onnx::MatMul_1819)\\n  %/vit/encoder/layer.6/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.6.intermediate.dense.bias, %/vit/encoder/layer.6/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.6/intermediate/dense/Add_output_0, %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.6/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.6/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.6/intermediate/dense/Add_output_0, %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.6/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.6/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.6/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.6/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1820)\\n  %/vit/encoder/layer.6/output/dense/Add_output_0 = Add(%vit.encoder.layer.6.output.dense.bias, %/vit/encoder/layer.6/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.6/output/Add_output_0 = Add(%/vit/encoder/layer.6/output/dense/Add_output_0, %/vit/encoder/layer.6/Add_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.6/output/Add_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.6/output/Add_output_0, %/vit/encoder/layer.7/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.7/layernorm_before/Sub_output_0, %/vit/encoder/layer.7/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.7/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.7/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.7/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.7/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.7/layernorm_before/Sub_output_0, %/vit/encoder/layer.7/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.7/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.7/layernorm_before/Div_output_0, %vit.encoder.layer.7.layernorm_before.weight)\\n  %/vit/encoder/layer.7/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.7/layernorm_before/Mul_output_0, %vit.encoder.layer.7.layernorm_before.bias)\\n  %/vit/encoder/layer.7/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/layernorm_before/Add_1_output_0, %onnx::MatMul_1821)\\n  %/vit/encoder/layer.7/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.7.attention.attention.query.bias, %/vit/encoder/layer.7/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.7/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/layernorm_before/Add_1_output_0, %onnx::MatMul_1822)\\n  %/vit/encoder/layer.7/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.7.attention.attention.key.bias, %/vit/encoder/layer.7/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.7/attention/attention/key/Add_output_0, %/vit/encoder/layer.7/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.7/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/layernorm_before/Add_1_output_0, %onnx::MatMul_1828)\\n  %/vit/encoder/layer.7/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.7.attention.attention.value.bias, %/vit/encoder/layer.7/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.7/attention/attention/value/Add_output_0, %/vit/encoder/layer.7/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.7/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.7/attention/attention/query/Add_output_0, %/vit/encoder/layer.7/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.7/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.7/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.7/attention/attention/Shape_output_0, %/vit/encoder/layer.7/attention/attention/Constant_3_output_0, %/vit/encoder/layer.7/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.7/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.7/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.7/attention/attention/Constant_5_output_0, %/vit/encoder/layer.7/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.7/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.7/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.7/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.7/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.7/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.7/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.7/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.7/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.7/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/attention/attention/Mul_output_0, %/vit/encoder/layer.7/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.7/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.7/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.7/attention/attention/Softmax_output_0, %/vit/encoder/layer.7/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.7/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.7/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.7/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.7/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.7/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.7/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/attention/attention/Reshape_3_output_0, %onnx::MatMul_1843)\\n  %/vit/encoder/layer.7/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.7.attention.output.dense.bias, %/vit/encoder/layer.7/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.7/Add_output_0 = Add(%/vit/encoder/layer.7/attention/output/dense/Add_output_0, %/vit/encoder/layer.6/output/Add_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.7/Add_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.7/Add_output_0, %/vit/encoder/layer.7/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.7/layernorm_after/Sub_output_0, %/vit/encoder/layer.7/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.7/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.7/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.7/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.7/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.7/layernorm_after/Sub_output_0, %/vit/encoder/layer.7/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.7/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.7/layernorm_after/Div_output_0, %vit.encoder.layer.7.layernorm_after.weight)\\n  %/vit/encoder/layer.7/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.7/layernorm_after/Mul_output_0, %vit.encoder.layer.7.layernorm_after.bias)\\n  %/vit/encoder/layer.7/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/layernorm_after/Add_1_output_0, %onnx::MatMul_1844)\\n  %/vit/encoder/layer.7/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.7.intermediate.dense.bias, %/vit/encoder/layer.7/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.7/intermediate/dense/Add_output_0, %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.7/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.7/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.7/intermediate/dense/Add_output_0, %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.7/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.7/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.7/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.7/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1845)\\n  %/vit/encoder/layer.7/output/dense/Add_output_0 = Add(%vit.encoder.layer.7.output.dense.bias, %/vit/encoder/layer.7/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.7/output/Add_output_0 = Add(%/vit/encoder/layer.7/output/dense/Add_output_0, %/vit/encoder/layer.7/Add_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.7/output/Add_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.7/output/Add_output_0, %/vit/encoder/layer.8/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.8/layernorm_before/Sub_output_0, %/vit/encoder/layer.8/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.8/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.8/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.8/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.8/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.8/layernorm_before/Sub_output_0, %/vit/encoder/layer.8/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.8/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.8/layernorm_before/Div_output_0, %vit.encoder.layer.8.layernorm_before.weight)\\n  %/vit/encoder/layer.8/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.8/layernorm_before/Mul_output_0, %vit.encoder.layer.8.layernorm_before.bias)\\n  %/vit/encoder/layer.8/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/layernorm_before/Add_1_output_0, %onnx::MatMul_1846)\\n  %/vit/encoder/layer.8/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.8.attention.attention.query.bias, %/vit/encoder/layer.8/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.8/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/layernorm_before/Add_1_output_0, %onnx::MatMul_1847)\\n  %/vit/encoder/layer.8/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.8.attention.attention.key.bias, %/vit/encoder/layer.8/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.8/attention/attention/key/Add_output_0, %/vit/encoder/layer.8/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.8/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/layernorm_before/Add_1_output_0, %onnx::MatMul_1853)\\n  %/vit/encoder/layer.8/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.8.attention.attention.value.bias, %/vit/encoder/layer.8/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.8/attention/attention/value/Add_output_0, %/vit/encoder/layer.8/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.8/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.8/attention/attention/query/Add_output_0, %/vit/encoder/layer.8/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.8/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.8/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.8/attention/attention/Shape_output_0, %/vit/encoder/layer.8/attention/attention/Constant_3_output_0, %/vit/encoder/layer.8/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.8/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.8/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.8/attention/attention/Constant_5_output_0, %/vit/encoder/layer.8/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.8/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.8/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.8/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.8/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.8/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.8/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.8/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.8/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.8/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/attention/attention/Mul_output_0, %/vit/encoder/layer.8/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.8/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.8/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.8/attention/attention/Softmax_output_0, %/vit/encoder/layer.8/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.8/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.8/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.8/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.8/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.8/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.8/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/attention/attention/Reshape_3_output_0, %onnx::MatMul_1868)\\n  %/vit/encoder/layer.8/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.8.attention.output.dense.bias, %/vit/encoder/layer.8/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.8/Add_output_0 = Add(%/vit/encoder/layer.8/attention/output/dense/Add_output_0, %/vit/encoder/layer.7/output/Add_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.8/Add_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.8/Add_output_0, %/vit/encoder/layer.8/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.8/layernorm_after/Sub_output_0, %/vit/encoder/layer.8/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.8/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.8/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.8/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.8/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.8/layernorm_after/Sub_output_0, %/vit/encoder/layer.8/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.8/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.8/layernorm_after/Div_output_0, %vit.encoder.layer.8.layernorm_after.weight)\\n  %/vit/encoder/layer.8/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.8/layernorm_after/Mul_output_0, %vit.encoder.layer.8.layernorm_after.bias)\\n  %/vit/encoder/layer.8/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/layernorm_after/Add_1_output_0, %onnx::MatMul_1869)\\n  %/vit/encoder/layer.8/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.8.intermediate.dense.bias, %/vit/encoder/layer.8/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.8/intermediate/dense/Add_output_0, %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.8/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.8/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.8/intermediate/dense/Add_output_0, %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.8/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.8/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.8/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.8/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1870)\\n  %/vit/encoder/layer.8/output/dense/Add_output_0 = Add(%vit.encoder.layer.8.output.dense.bias, %/vit/encoder/layer.8/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.8/output/Add_output_0 = Add(%/vit/encoder/layer.8/output/dense/Add_output_0, %/vit/encoder/layer.8/Add_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.8/output/Add_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.8/output/Add_output_0, %/vit/encoder/layer.9/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.9/layernorm_before/Sub_output_0, %/vit/encoder/layer.9/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.9/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.9/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.9/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.9/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.9/layernorm_before/Sub_output_0, %/vit/encoder/layer.9/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.9/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.9/layernorm_before/Div_output_0, %vit.encoder.layer.9.layernorm_before.weight)\\n  %/vit/encoder/layer.9/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.9/layernorm_before/Mul_output_0, %vit.encoder.layer.9.layernorm_before.bias)\\n  %/vit/encoder/layer.9/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/layernorm_before/Add_1_output_0, %onnx::MatMul_1871)\\n  %/vit/encoder/layer.9/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.9.attention.attention.query.bias, %/vit/encoder/layer.9/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.9/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/layernorm_before/Add_1_output_0, %onnx::MatMul_1872)\\n  %/vit/encoder/layer.9/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.9.attention.attention.key.bias, %/vit/encoder/layer.9/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.9/attention/attention/key/Add_output_0, %/vit/encoder/layer.9/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.9/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/layernorm_before/Add_1_output_0, %onnx::MatMul_1878)\\n  %/vit/encoder/layer.9/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.9.attention.attention.value.bias, %/vit/encoder/layer.9/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.9/attention/attention/value/Add_output_0, %/vit/encoder/layer.9/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.9/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.9/attention/attention/query/Add_output_0, %/vit/encoder/layer.9/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.9/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.9/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.9/attention/attention/Shape_output_0, %/vit/encoder/layer.9/attention/attention/Constant_3_output_0, %/vit/encoder/layer.9/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.9/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.9/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.9/attention/attention/Constant_5_output_0, %/vit/encoder/layer.9/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.9/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.9/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.9/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.9/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.9/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.9/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.9/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.9/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.9/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/attention/attention/Mul_output_0, %/vit/encoder/layer.9/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.9/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.9/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.9/attention/attention/Softmax_output_0, %/vit/encoder/layer.9/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.9/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.9/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.9/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.9/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.9/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.9/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/attention/attention/Reshape_3_output_0, %onnx::MatMul_1893)\\n  %/vit/encoder/layer.9/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.9.attention.output.dense.bias, %/vit/encoder/layer.9/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.9/Add_output_0 = Add(%/vit/encoder/layer.9/attention/output/dense/Add_output_0, %/vit/encoder/layer.8/output/Add_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.9/Add_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.9/Add_output_0, %/vit/encoder/layer.9/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.9/layernorm_after/Sub_output_0, %/vit/encoder/layer.9/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.9/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.9/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.9/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.9/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.9/layernorm_after/Sub_output_0, %/vit/encoder/layer.9/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.9/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.9/layernorm_after/Div_output_0, %vit.encoder.layer.9.layernorm_after.weight)\\n  %/vit/encoder/layer.9/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.9/layernorm_after/Mul_output_0, %vit.encoder.layer.9.layernorm_after.bias)\\n  %/vit/encoder/layer.9/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/layernorm_after/Add_1_output_0, %onnx::MatMul_1894)\\n  %/vit/encoder/layer.9/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.9.intermediate.dense.bias, %/vit/encoder/layer.9/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.9/intermediate/dense/Add_output_0, %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.9/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.9/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.9/intermediate/dense/Add_output_0, %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.9/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.9/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.9/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.9/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1895)\\n  %/vit/encoder/layer.9/output/dense/Add_output_0 = Add(%vit.encoder.layer.9.output.dense.bias, %/vit/encoder/layer.9/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.9/output/Add_output_0 = Add(%/vit/encoder/layer.9/output/dense/Add_output_0, %/vit/encoder/layer.9/Add_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.9/output/Add_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.9/output/Add_output_0, %/vit/encoder/layer.10/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.10/layernorm_before/Sub_output_0, %/vit/encoder/layer.10/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.10/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.10/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.10/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.10/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.10/layernorm_before/Sub_output_0, %/vit/encoder/layer.10/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.10/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.10/layernorm_before/Div_output_0, %vit.encoder.layer.10.layernorm_before.weight)\\n  %/vit/encoder/layer.10/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.10/layernorm_before/Mul_output_0, %vit.encoder.layer.10.layernorm_before.bias)\\n  %/vit/encoder/layer.10/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/layernorm_before/Add_1_output_0, %onnx::MatMul_1896)\\n  %/vit/encoder/layer.10/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.10.attention.attention.query.bias, %/vit/encoder/layer.10/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.10/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/layernorm_before/Add_1_output_0, %onnx::MatMul_1897)\\n  %/vit/encoder/layer.10/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.10.attention.attention.key.bias, %/vit/encoder/layer.10/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.10/attention/attention/key/Add_output_0, %/vit/encoder/layer.10/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.10/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/layernorm_before/Add_1_output_0, %onnx::MatMul_1903)\\n  %/vit/encoder/layer.10/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.10.attention.attention.value.bias, %/vit/encoder/layer.10/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.10/attention/attention/value/Add_output_0, %/vit/encoder/layer.10/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.10/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.10/attention/attention/query/Add_output_0, %/vit/encoder/layer.10/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.10/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.10/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.10/attention/attention/Shape_output_0, %/vit/encoder/layer.10/attention/attention/Constant_3_output_0, %/vit/encoder/layer.10/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.10/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.10/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.10/attention/attention/Constant_5_output_0, %/vit/encoder/layer.10/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.10/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.10/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.10/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.10/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.10/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.10/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.10/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.10/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.10/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/attention/attention/Mul_output_0, %/vit/encoder/layer.10/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.10/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.10/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.10/attention/attention/Softmax_output_0, %/vit/encoder/layer.10/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.10/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.10/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.10/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.10/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.10/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.10/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/attention/attention/Reshape_3_output_0, %onnx::MatMul_1918)\\n  %/vit/encoder/layer.10/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.10.attention.output.dense.bias, %/vit/encoder/layer.10/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.10/Add_output_0 = Add(%/vit/encoder/layer.10/attention/output/dense/Add_output_0, %/vit/encoder/layer.9/output/Add_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.10/Add_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.10/Add_output_0, %/vit/encoder/layer.10/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.10/layernorm_after/Sub_output_0, %/vit/encoder/layer.10/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.10/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.10/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.10/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.10/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.10/layernorm_after/Sub_output_0, %/vit/encoder/layer.10/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.10/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.10/layernorm_after/Div_output_0, %vit.encoder.layer.10.layernorm_after.weight)\\n  %/vit/encoder/layer.10/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.10/layernorm_after/Mul_output_0, %vit.encoder.layer.10.layernorm_after.bias)\\n  %/vit/encoder/layer.10/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/layernorm_after/Add_1_output_0, %onnx::MatMul_1919)\\n  %/vit/encoder/layer.10/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.10.intermediate.dense.bias, %/vit/encoder/layer.10/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.10/intermediate/dense/Add_output_0, %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.10/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.10/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.10/intermediate/dense/Add_output_0, %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.10/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.10/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.10/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.10/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1920)\\n  %/vit/encoder/layer.10/output/dense/Add_output_0 = Add(%vit.encoder.layer.10.output.dense.bias, %/vit/encoder/layer.10/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.10/output/Add_output_0 = Add(%/vit/encoder/layer.10/output/dense/Add_output_0, %/vit/encoder/layer.10/Add_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.10/output/Add_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/Sub_output_0 = Sub(%/vit/encoder/layer.10/output/Add_output_0, %/vit/encoder/layer.11/layernorm_before/ReduceMean_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/layernorm_before/Pow_output_0 = Pow(%/vit/encoder/layer.11/layernorm_before/Sub_output_0, %/vit/encoder/layer.11/layernorm_before/Constant_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.11/layernorm_before/Pow_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/layernorm_before/Add_output_0 = Add(%/vit/encoder/layer.11/layernorm_before/ReduceMean_1_output_0, %/vit/encoder/layer.11/layernorm_before/Constant_1_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.11/layernorm_before/Add_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/Div_output_0 = Div(%/vit/encoder/layer.11/layernorm_before/Sub_output_0, %/vit/encoder/layer.11/layernorm_before/Sqrt_output_0)\\n  %/vit/encoder/layer.11/layernorm_before/Mul_output_0 = Mul(%/vit/encoder/layer.11/layernorm_before/Div_output_0, %vit.encoder.layer.11.layernorm_before.weight)\\n  %/vit/encoder/layer.11/layernorm_before/Add_1_output_0 = Add(%/vit/encoder/layer.11/layernorm_before/Mul_output_0, %vit.encoder.layer.11.layernorm_before.bias)\\n  %/vit/encoder/layer.11/attention/attention/query/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/layernorm_before/Add_1_output_0, %onnx::MatMul_1921)\\n  %/vit/encoder/layer.11/attention/attention/query/Add_output_0 = Add(%vit.encoder.layer.11.attention.attention.query.bias, %/vit/encoder/layer.11/attention/attention/query/MatMul_output_0)\\n  %/vit/encoder/layer.11/attention/attention/key/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/layernorm_before/Add_1_output_0, %onnx::MatMul_1922)\\n  %/vit/encoder/layer.11/attention/attention/key/Add_output_0 = Add(%vit.encoder.layer.11.attention.attention.key.bias, %/vit/encoder/layer.11/attention/attention/key/MatMul_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Constant_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Reshape_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.11/attention/attention/key/Add_output_0, %/vit/encoder/layer.11/attention/attention/Constant_output_0)\\n  %/vit/encoder/layer.11/attention/attention/value/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/layernorm_before/Add_1_output_0, %onnx::MatMul_1928)\\n  %/vit/encoder/layer.11/attention/attention/value/Add_output_0 = Add(%vit.encoder.layer.11.attention.attention.value.bias, %/vit/encoder/layer.11/attention/attention/value/MatMul_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Constant_1_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Reshape_1_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.11/attention/attention/value/Add_output_0, %/vit/encoder/layer.11/attention/attention/Constant_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Transpose_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.11/attention/attention/Reshape_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Constant_2_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Reshape_2_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.11/attention/attention/query/Add_output_0, %/vit/encoder/layer.11/attention/attention/Constant_2_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Transpose_1_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.11/attention/attention/Reshape_2_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Shape_output_0 = Shape(%/vit/encoder/layer.11/attention/attention/Transpose_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Constant_3_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Constant_4_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Slice_output_0 = Slice(%/vit/encoder/layer.11/attention/attention/Shape_output_0, %/vit/encoder/layer.11/attention/attention/Constant_3_output_0, %/vit/encoder/layer.11/attention/attention/Constant_4_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Cast_output_0 = Cast[to = 1](%/vit/encoder/layer.11/attention/attention/Slice_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.11/attention/attention/Cast_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Constant_5_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Div_output_0 = Div(%/vit/encoder/layer.11/attention/attention/Constant_5_output_0, %/vit/encoder/layer.11/attention/attention/Sqrt_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Cast_1_output_0 = Cast[to = 1](%/vit/encoder/layer.11/attention/attention/Div_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Transpose_2_output_0 = Transpose[perm = [0, 2, 3, 1]](%/vit/encoder/layer.11/attention/attention/Reshape_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Sqrt_1_output_0 = Sqrt(%/vit/encoder/layer.11/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Mul_output_0 = Mul(%/vit/encoder/layer.11/attention/attention/Transpose_1_output_0, %/vit/encoder/layer.11/attention/attention/Sqrt_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Sqrt_2_output_0 = Sqrt(%/vit/encoder/layer.11/attention/attention/Cast_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Mul_1_output_0 = Mul(%/vit/encoder/layer.11/attention/attention/Transpose_2_output_0, %/vit/encoder/layer.11/attention/attention/Sqrt_2_output_0)\\n  %/vit/encoder/layer.11/attention/attention/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/attention/attention/Mul_output_0, %/vit/encoder/layer.11/attention/attention/Mul_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Softmax_output_0 = Softmax[axis = -1](%/vit/encoder/layer.11/attention/attention/MatMul_output_0)\\n  %/vit/encoder/layer.11/attention/attention/MatMul_1_output_0 = MatMul(%/vit/encoder/layer.11/attention/attention/Softmax_output_0, %/vit/encoder/layer.11/attention/attention/Transpose_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Transpose_3_output_0 = Transpose[perm = [0, 2, 1, 3]](%/vit/encoder/layer.11/attention/attention/MatMul_1_output_0)\\n  %/vit/encoder/layer.11/attention/attention/Constant_6_output_0 = Constant[value = <Tensor>]()\\n  %/vit/encoder/layer.11/attention/attention/Reshape_3_output_0 = Reshape[allowzero = 0](%/vit/encoder/layer.11/attention/attention/Transpose_3_output_0, %/vit/encoder/layer.11/attention/attention/Constant_6_output_0)\\n  %/vit/encoder/layer.11/attention/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/attention/attention/Reshape_3_output_0, %onnx::MatMul_1943)\\n  %/vit/encoder/layer.11/attention/output/dense/Add_output_0 = Add(%vit.encoder.layer.11.attention.output.dense.bias, %/vit/encoder/layer.11/attention/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.11/Add_output_0 = Add(%/vit/encoder/layer.11/attention/output/dense/Add_output_0, %/vit/encoder/layer.10/output/Add_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.11/Add_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/Sub_output_0 = Sub(%/vit/encoder/layer.11/Add_output_0, %/vit/encoder/layer.11/layernorm_after/ReduceMean_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/layernorm_after/Pow_output_0 = Pow(%/vit/encoder/layer.11/layernorm_after/Sub_output_0, %/vit/encoder/layer.11/layernorm_after/Constant_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.11/layernorm_after/Pow_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/layernorm_after/Add_output_0 = Add(%/vit/encoder/layer.11/layernorm_after/ReduceMean_1_output_0, %/vit/encoder/layer.11/layernorm_after/Constant_1_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/Sqrt_output_0 = Sqrt(%/vit/encoder/layer.11/layernorm_after/Add_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/Div_output_0 = Div(%/vit/encoder/layer.11/layernorm_after/Sub_output_0, %/vit/encoder/layer.11/layernorm_after/Sqrt_output_0)\\n  %/vit/encoder/layer.11/layernorm_after/Mul_output_0 = Mul(%/vit/encoder/layer.11/layernorm_after/Div_output_0, %vit.encoder.layer.11.layernorm_after.weight)\\n  %/vit/encoder/layer.11/layernorm_after/Add_1_output_0 = Add(%/vit/encoder/layer.11/layernorm_after/Mul_output_0, %vit.encoder.layer.11.layernorm_after.bias)\\n  %/vit/encoder/layer.11/intermediate/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/layernorm_after/Add_1_output_0, %onnx::MatMul_1944)\\n  %/vit/encoder/layer.11/intermediate/dense/Add_output_0 = Add(%vit.encoder.layer.11.intermediate.dense.bias, %/vit/encoder/layer.11/intermediate/dense/MatMul_output_0)\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0 = Div(%/vit/encoder/layer.11/intermediate/dense/Add_output_0, %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Constant_output_0)\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Erf_output_0 = Erf(%/vit/encoder/layer.11/intermediate/intermediate_act_fn/Div_output_0)\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0 = Add(%/vit/encoder/layer.11/intermediate/intermediate_act_fn/Erf_output_0, %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Constant_1_output_0)\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Mul_output_0 = Mul(%/vit/encoder/layer.11/intermediate/dense/Add_output_0, %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Add_output_0)\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Constant_2_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0 = Mul(%/vit/encoder/layer.11/intermediate/intermediate_act_fn/Mul_output_0, %/vit/encoder/layer.11/intermediate/intermediate_act_fn/Constant_2_output_0)\\n  %/vit/encoder/layer.11/output/dense/MatMul_output_0 = MatMul(%/vit/encoder/layer.11/intermediate/intermediate_act_fn/Mul_1_output_0, %onnx::MatMul_1945)\\n  %/vit/encoder/layer.11/output/dense/Add_output_0 = Add(%vit.encoder.layer.11.output.dense.bias, %/vit/encoder/layer.11/output/dense/MatMul_output_0)\\n  %/vit/encoder/layer.11/output/Add_output_0 = Add(%/vit/encoder/layer.11/output/dense/Add_output_0, %/vit/encoder/layer.11/Add_output_0)\\n  %/vit/layernorm/ReduceMean_output_0 = ReduceMean[axes = [-1]](%/vit/encoder/layer.11/output/Add_output_0)\\n  %/vit/layernorm/Sub_output_0 = Sub(%/vit/encoder/layer.11/output/Add_output_0, %/vit/layernorm/ReduceMean_output_0)\\n  %/vit/layernorm/Constant_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/layernorm/Pow_output_0 = Pow(%/vit/layernorm/Sub_output_0, %/vit/layernorm/Constant_output_0)\\n  %/vit/layernorm/ReduceMean_1_output_0 = ReduceMean[axes = [-1]](%/vit/layernorm/Pow_output_0)\\n  %/vit/layernorm/Constant_1_output_0 = Constant[value = <Scalar Tensor []>]()\\n  %/vit/layernorm/Add_output_0 = Add(%/vit/layernorm/ReduceMean_1_output_0, %/vit/layernorm/Constant_1_output_0)\\n  %/vit/layernorm/Sqrt_output_0 = Sqrt(%/vit/layernorm/Add_output_0)\\n  %/vit/layernorm/Div_output_0 = Div(%/vit/layernorm/Sub_output_0, %/vit/layernorm/Sqrt_output_0)\\n  %/vit/layernorm/Mul_output_0 = Mul(%/vit/layernorm/Div_output_0, %vit.layernorm.weight)\\n  %/vit/layernorm/Add_1_output_0 = Add(%/vit/layernorm/Mul_output_0, %vit.layernorm.bias)\\n  %/Gather_output_0 = Gather[axis = 1](%/vit/layernorm/Add_1_output_0, %/vit/embeddings/Constant_output_0)\\n  %1639 = Gemm[alpha = 1, beta = 1, transB = 1](%/Gather_output_0, %classifier.weight, %classifier.bias)\\n  return %1639\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "biZgFIz0_eJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4fdeb7-c69e-4c3b-b379-e01cfc227db2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "ort_session = ort.InferenceSession('odel-swin.onnx')\n",
        "outputs = ort_session.run(\n",
        "    None,\n",
        "    {'input.1': np.random.randn(1, 3, 224, 224).astype(np.float32)}\n",
        ")"
      ],
      "metadata": {
        "id": "v6MWMAsdJVxN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/onnx/onnx-tensorflow.git && cd onnx-tensorflow\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "_8IIloFPJXMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95545618-0f8d-429f-a440-bf7b4444b57a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'onnx-tensorflow'...\n",
            "remote: Enumerating objects: 6516, done.\u001b[K\n",
            "remote: Counting objects: 100% (465/465), done.\u001b[K\n",
            "remote: Compressing objects: 100% (200/200), done.\u001b[K\n",
            "remote: Total 6516 (delta 326), reused 383 (delta 261), pack-reused 6051\u001b[K\n",
            "Receiving objects: 100% (6516/6516), 1.98 MiB | 13.90 MiB/s, done.\n",
            "Resolving deltas: 100% (5051/5051), done.\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load('odel-swin.onnx')"
      ],
      "metadata": {
        "id": "DHvyDbjfJaUd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx-tf\n",
        "from onnx_tf.backend import prepare"
      ],
      "metadata": {
        "id": "Rt56Rzz8JcaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09c3ed8-4346-491e-eee2-94fbfd5643d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (1.16.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (6.0.1)\n",
            "Collecting tensorflow-addons (from onnx-tf)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->onnx-tf) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx-tf)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx import helper\n",
        "\n",
        "onnx_model = onnx.load('odel-swin.onnx')\n",
        "\n",
        "# Define a mapping from old names to new names\n",
        "name_map = {\"input.1\": \"input_1\"}\n",
        "\n",
        "# Initialize a list to hold the new inputs\n",
        "new_inputs = []\n",
        "\n",
        "# Iterate over the inputs and change their names if needed\n",
        "for inp in onnx_model.graph.input:\n",
        "    if inp.name in name_map:\n",
        "        # Create a new ValueInfoProto with the new name\n",
        "        new_inp = helper.make_tensor_value_info(name_map[inp.name],\n",
        "                                                inp.type.tensor_type.elem_type,\n",
        "                                                [dim.dim_value for dim in inp.type.tensor_type.shape.dim])\n",
        "        new_inputs.append(new_inp)\n",
        "    else:\n",
        "        new_inputs.append(inp)\n",
        "\n",
        "# Clear the old inputs and add the new ones\n",
        "onnx_model.graph.ClearField(\"input\")\n",
        "onnx_model.graph.input.extend(new_inputs)\n",
        "\n",
        "# Go through all nodes in the model and replace the old input name with the new one\n",
        "for node in onnx_model.graph.node:\n",
        "    for i, input_name in enumerate(node.input):\n",
        "        if input_name in name_map:\n",
        "            node.input[i] = name_map[input_name]\n",
        "\n",
        "# Save the renamed ONNX model\n",
        "onnx.save(onnx_model, 'model-swin.onnx')"
      ],
      "metadata": {
        "id": "439H844SJeVS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "34bd6fbe-995f-4c25-d21e-00767c9cae89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'onnx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-66b00c799c44>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'odel-swin.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnx'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the ONNX model\n",
        "model = onnx.load('model-swin.onnx')\n",
        "\n",
        "# Print the names of the inputs\n",
        "for input in model.graph.input:\n",
        "    print(\"Input name:\", input.name)\n"
      ],
      "metadata": {
        "id": "2LJfetoMJgds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86a4ef3-f73d-4078-f03f-252306cc9348"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input name: input_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the input tensor\n",
        "input_tensor = np.random.randn(1, 3, 224, 224).astype(np.float32)\n",
        "\n",
        "# Prepare the TensorFlow representation\n",
        "tf_rep = prepare(onnx_model, input_shapes={'input.1': [1, 3, 224, 224]})"
      ],
      "metadata": {
        "id": "UJHVdvhQJiBf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_rep.export_graph('modelbismillah.h5')"
      ],
      "metadata": {
        "id": "x1Bb0OQwJlb8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.saved_model.load('modelbismillah.h5')\n",
        "model.trainable = False\n",
        "input_tensor = tf.random.uniform([1, 3, 224, 224])\n",
        "out = model(input_1=input_tensor)"
      ],
      "metadata": {
        "id": "7LbaYCRjJnaL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "try:\n",
        "    # Convert the TensorFlow model to TensorFlow Lite\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(\"modelbismillah.h5\")\n",
        "\n",
        "    # Enable TensorFlow Select ops\n",
        "    converter.target_spec.supported_ops = [\n",
        "        tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
        "        tf.lite.OpsSet.SELECT_TF_OPS     # Enable TensorFlow Select ops.\n",
        "    ]\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TensorFlow Lite model\n",
        "    with open(\"simple_model.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"Model conversion successful and saved as 'simple_model.tflite'.\")\n",
        "except Exception as e:\n",
        "    print(\"Error during model conversion:\", str(e))"
      ],
      "metadata": {
        "id": "cl7dKnlzJooj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df041475-322c-42db-b3da-ae20118d4ac6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error during model conversion: SavedModel file does not exist at: modelbismillah.h5/{saved_model.pbtxt|saved_model.pb}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A-we8_-i0y_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de544e4-5776-436f-ffa6-1e314e84556f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.2821207   0.77802527  0.40348542 -0.60586274 -2.4083736 ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path=\"simple_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model on random input data\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# get_tensor() returns a copy of the tensor data\n",
        "# use tensor() in order to get a pointer to the tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}